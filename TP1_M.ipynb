{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce1fb68",
   "metadata": {},
   "source": [
    "## TP1 d'Apprentissage Statistique \n",
    "\n",
    "### Binome:\n",
    "- NKOUNGHAWE TOMEYUM Rosalie Corine\n",
    "- LENO Celestine  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6a83a",
   "metadata": {},
   "source": [
    "### A- Les données \n",
    "\n",
    "La fonction qui permet d'engendrer une matrice dont chaque valeur est une observation d'une personne avec 3 caractéristiques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9afd212e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('B', 'T', 'P'), ('B', 'S', 'G'), ('B', 'S', 'P')], [('B', 'S', 'G'), ('B', 'T', 'P'), ('D', 'T', 'G')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('D', 'T', 'P')], [('B', 'T', 'P'), ('B', 'S', 'G'), ('B', 'S', 'P')], [('D', 'T', 'G'), ('B', 'T', 'P'), ('D', 'S', 'G')], [('D', 'S', 'P'), ('D', 'T', 'G'), ('D', 'T', 'P')], [('B', 'T', 'P'), ('D', 'S', 'P'), ('B', 'S', 'G')], [('D', 'T', 'P'), ('B', 'T', 'P'), ('D', 'T', 'P')], [('D', 'T', 'P'), ('D', 'S', 'P'), ('D', 'S', 'G')], [('B', 'S', 'P'), ('B', 'S', 'P'), ('B', 'S', 'P')], [('B', 'S', 'P'), ('D', 'S', 'P'), ('B', 'S', 'G')], [('B', 'S', 'P'), ('B', 'T', 'P'), ('B', 'T', 'G')], [('B', 'T', 'G'), ('D', 'T', 'P'), ('D', 'T', 'P')], [('D', 'S', 'G'), ('B', 'T', 'G'), ('D', 'T', 'G')], [('D', 'T', 'G'), ('B', 'S', 'G'), ('D', 'S', 'P')], [('D', 'S', 'G'), ('D', 'S', 'P'), ('B', 'S', 'P')], [('B', 'S', 'P'), ('B', 'S', 'G'), ('D', 'S', 'P')], [('B', 'T', 'G'), ('B', 'S', 'G'), ('B', 'T', 'P')], [('D', 'S', 'P'), ('D', 'T', 'G'), ('D', 'S', 'G')], [('D', 'S', 'G'), ('D', 'S', 'P'), ('D', 'T', 'P')], [('B', 'S', 'P'), ('D', 'T', 'P'), ('D', 'S', 'G')], [('D', 'T', 'G'), ('D', 'T', 'G'), ('D', 'T', 'P')], [('B', 'T', 'P'), ('D', 'S', 'G'), ('D', 'S', 'P')], [('D', 'S', 'P'), ('D', 'T', 'P'), ('B', 'T', 'P')], [('B', 'T', 'G'), ('B', 'T', 'G'), ('B', 'T', 'G')], [('B', 'S', 'G'), ('B', 'S', 'P'), ('D', 'T', 'G')], [('B', 'S', 'G'), ('B', 'S', 'P'), ('D', 'T', 'G')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('D', 'S', 'G')], [('D', 'T', 'P'), ('D', 'T', 'P'), ('D', 'S', 'G')], [('D', 'T', 'P'), ('D', 'S', 'P'), ('D', 'S', 'G')], [('B', 'S', 'P'), ('B', 'S', 'P'), ('D', 'T', 'P')], [('D', 'T', 'P'), ('B', 'S', 'P'), ('D', 'S', 'P')], [('B', 'T', 'G'), ('B', 'S', 'P'), ('B', 'S', 'P')], [('D', 'T', 'G'), ('D', 'T', 'P'), ('B', 'S', 'P')], [('D', 'S', 'P'), ('D', 'S', 'P'), ('D', 'S', 'P')], [('B', 'T', 'G'), ('D', 'T', 'G'), ('B', 'T', 'P')], [('D', 'S', 'G'), ('B', 'S', 'G'), ('D', 'T', 'P')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('B', 'S', 'G')], [('B', 'S', 'P'), ('D', 'S', 'P'), ('B', 'T', 'P')], [('D', 'T', 'G'), ('D', 'S', 'G'), ('B', 'T', 'G')], [('D', 'T', 'G'), ('B', 'S', 'G'), ('D', 'S', 'P')], [('D', 'S', 'P'), ('B', 'T', 'G'), ('B', 'S', 'G')], [('B', 'T', 'G'), ('B', 'T', 'G'), ('D', 'S', 'P')], [('D', 'T', 'G'), ('D', 'S', 'P'), ('B', 'T', 'P')], [('B', 'S', 'G'), ('B', 'T', 'P'), ('B', 'T', 'G')], [('B', 'S', 'P'), ('D', 'T', 'P'), ('D', 'S', 'P')], [('D', 'S', 'G'), ('B', 'S', 'P'), ('D', 'T', 'G')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('D', 'S', 'G')], [('D', 'S', 'G'), ('D', 'S', 'P'), ('D', 'S', 'G')], [('B', 'S', 'P'), ('D', 'S', 'P'), ('B', 'S', 'G')], [('D', 'S', 'P'), ('B', 'S', 'G'), ('D', 'S', 'G')], [('B', 'S', 'P'), ('D', 'T', 'G'), ('D', 'T', 'P')], [('D', 'S', 'G'), ('B', 'T', 'G'), ('D', 'T', 'P')], [('B', 'T', 'G'), ('D', 'T', 'G'), ('D', 'S', 'P')], [('D', 'S', 'P'), ('B', 'S', 'G'), ('D', 'T', 'G')], [('B', 'S', 'P'), ('D', 'S', 'G'), ('D', 'S', 'P')], [('B', 'S', 'P'), ('D', 'S', 'P'), ('D', 'S', 'G')], [('B', 'S', 'G'), ('D', 'T', 'P'), ('D', 'S', 'P')], [('B', 'S', 'G'), ('B', 'S', 'G'), ('D', 'T', 'P')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('D', 'S', 'P')], [('B', 'S', 'P'), ('D', 'S', 'G'), ('B', 'T', 'P')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('B', 'S', 'G')], [('B', 'S', 'G'), ('D', 'S', 'P'), ('D', 'T', 'G')], [('D', 'T', 'G'), ('B', 'T', 'P'), ('B', 'S', 'G')], [('B', 'S', 'P'), ('D', 'S', 'G'), ('D', 'S', 'G')], [('B', 'S', 'P'), ('D', 'S', 'P'), ('D', 'S', 'G')], [('D', 'S', 'G'), ('B', 'S', 'P'), ('D', 'S', 'G')], [('D', 'S', 'G'), ('B', 'S', 'P'), ('B', 'S', 'G')], [('B', 'S', 'G'), ('B', 'T', 'P'), ('D', 'T', 'P')], [('B', 'T', 'P'), ('D', 'S', 'G'), ('B', 'T', 'P')], [('D', 'T', 'P'), ('D', 'S', 'P'), ('B', 'S', 'G')], [('B', 'T', 'P'), ('D', 'T', 'P'), ('B', 'S', 'G')], [('D', 'S', 'P'), ('D', 'S', 'G'), ('B', 'S', 'G')], [('D', 'T', 'G'), ('D', 'S', 'P'), ('B', 'T', 'G')], [('B', 'S', 'P'), ('B', 'T', 'G'), ('B', 'S', 'P')], [('D', 'S', 'G'), ('D', 'T', 'P'), ('D', 'S', 'G')], [('D', 'T', 'P'), ('D', 'T', 'P'), ('B', 'S', 'P')], [('B', 'S', 'P'), ('B', 'T', 'P'), ('B', 'T', 'G')], [('B', 'S', 'G'), ('B', 'T', 'G'), ('B', 'T', 'G')], [('D', 'T', 'G'), ('D', 'T', 'G'), ('D', 'T', 'G')], [('B', 'T', 'G'), ('D', 'T', 'P'), ('B', 'T', 'P')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('D', 'S', 'G')], [('D', 'T', 'G'), ('D', 'S', 'G'), ('B', 'S', 'P')], [('D', 'T', 'P'), ('D', 'T', 'G'), ('D', 'T', 'G')], [('B', 'S', 'P'), ('D', 'S', 'P'), ('D', 'T', 'G')], [('B', 'S', 'P'), ('B', 'S', 'P'), ('D', 'S', 'P')], [('B', 'S', 'P'), ('D', 'S', 'P'), ('B', 'S', 'G')], [('B', 'T', 'G'), ('D', 'T', 'P'), ('B', 'T', 'P')], [('B', 'S', 'P'), ('D', 'T', 'P'), ('D', 'S', 'G')], [('B', 'T', 'P'), ('B', 'T', 'P'), ('D', 'T', 'P')], [('B', 'S', 'G'), ('D', 'T', 'G'), ('D', 'S', 'P')], [('D', 'T', 'G'), ('B', 'S', 'G'), ('B', 'T', 'G')], [('B', 'S', 'P'), ('D', 'S', 'G'), ('D', 'S', 'P')], [('B', 'T', 'G'), ('B', 'T', 'G'), ('D', 'S', 'P')], [('D', 'S', 'P'), ('D', 'T', 'G'), ('D', 'S', 'G')], [('D', 'S', 'P'), ('B', 'T', 'P'), ('B', 'T', 'G')], [('D', 'T', 'G'), ('D', 'S', 'P'), ('B', 'T', 'P')], [('D', 'T', 'G'), ('D', 'T', 'P'), ('B', 'S', 'G')], [('D', 'T', 'P'), ('B', 'S', 'P'), ('D', 'S', 'P')], [('B', 'S', 'G'), ('D', 'T', 'P'), ('D', 'T', 'P')]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "\n",
    "def generer_tableau(n): # n est le nombre de lignes de la matrice, le nombre de colonnes est 3\n",
    "\n",
    "    # Nous définissons les domaines de chaque observation, dans lesquels nous allons faire la sélection des valeurs \n",
    "    # pour former la matrice \n",
    "\n",
    "    cheveux = ['B', 'D']   # Blond, Dark\n",
    "    hauteur = ['T', 'S']   # Tall, Short\n",
    "    pays = ['G', 'P']      # Greenland, Poland\n",
    "    \n",
    "    tableau = []\n",
    "    for _ in range(n):  # pour chaque ligne\n",
    "        ligne = []\n",
    "        for _ in range(3):  # 3 colonnes\n",
    "            c = random.choice(cheveux)\n",
    "            h = random.choice(hauteur)\n",
    "            p = random.choice(pays)\n",
    "            ligne.append((c, h, p))  # un triplet\n",
    "        tableau.append(ligne)\n",
    "    return tableau\n",
    "\n",
    "# Générons une matrice un peu plus grande avec 100 lignes \n",
    "print(generer_tableau(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fa0a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La matrice que nous allons utiliser \n",
    "\n",
    "# Pour controler l'aléa \n",
    "random.seed(42)\n",
    "data = generer_tableau(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800278f",
   "metadata": {},
   "source": [
    "### B- Questions : nationalité la plus probable d'un individu grand (T) et qui a les cheveux Blond (B)\n",
    "\n",
    "Les fonctions que nous allons écrire dans la suite sont par rapport à la matrice que nous avons définie\n",
    "\n",
    "### C- Maximum a posteriori\n",
    "Nous allons utiliser deux versions de cette métrique pour conclure sur la question:  \n",
    "- Une qui se fera avec naive bayes \n",
    "- Une autre qui ne tiendra pas compte de navive bayes : se basera uniquement sur les fréquences d'apparution, via la formule des probabilités conditionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a46fec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nous allons donc faire le calcul de probabilité avec plusieurs petites fonctions que nous allons utiliser\n",
    "# par la suite dans une fonction générale \n",
    "\n",
    "##1- Version avec le théorème de bayes\n",
    "\n",
    "\"\"\"\n",
    "Il s'agit de calculer deux probabilités a posteriori et de prendre le maximum afin de conclure sur la nationalité de l'individu\n",
    "Les formules sont les suivantes: \n",
    "\n",
    "P(G/B,T) = P(G)*P(B,T/G) / P(B,T)\n",
    "P(P/B,T) = P(P)*P(B,T/P) / P(B,T)\n",
    "\n",
    "Nous aurons besoin de caluler :\n",
    "P(G): pg(), \n",
    "P(P): pp(), \n",
    "P(B,T/G): pbtg(), \n",
    "P(B,T/P): pbtp() \n",
    "et P(B,T): pbt()\n",
    "\n",
    "P(G) = nombre de personnes de nationalité G / nombre total d'individus\n",
    "P(P) = nombre de personnes de nationalité P / nombre total d'individus\n",
    "\n",
    "P(B,T/G) = P(B/G)*P(T/G) via l'hypothèse d'indépendance de naive bayes\n",
    "P(B/G) : pbg() = nombre de personnes aux cheveux Blonds / nombre de personnes de nationalité G\n",
    "P(T/G) : ptg() = nombre de personnes de hauteur T / nombre de personnes de nationalité G\n",
    "\n",
    "P(B,T/P) = P(B/P)*P(T/P) pareil que précédemment pour la nationalité G\n",
    "P(B/P) : pbp() = nombre de personnes aux cheveux Blonds / nombre de personnes de nationalité P\n",
    "P(T/P) : ptp() = nombre de personnes de hauteur T / nombre de personnes de nationalité P\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# -------------- Fonctions utilitaires -------------------- #\n",
    "\n",
    "\n",
    "def pg(data):\n",
    "    nb_G = 0\n",
    "    nb_Total = len(data) * len(data[0])\n",
    "    for ligne in data:\n",
    "        for indiv in ligne:\n",
    "            if indiv[2] == 'G':\n",
    "                nb_G += 1\n",
    "    return nb_G / nb_Total\n",
    "\n",
    "def pp(data):\n",
    "    nb_P = 0\n",
    "    nb_Total = len(data) * len(data[0])\n",
    "    for ligne in data:\n",
    "        for indiv in ligne:\n",
    "            if indiv[2] == 'P':\n",
    "                nb_P += 1\n",
    "    return nb_P / nb_Total\n",
    "\n",
    "def pbg(data):\n",
    "    nb_blond_G, nb_G = 0, 0\n",
    "    for ligne in data:\n",
    "        for indiv in ligne:\n",
    "            if indiv[2] == 'G':\n",
    "                nb_G += 1\n",
    "                if indiv[0] == 'B':  # cheveux blonds\n",
    "                    nb_blond_G += 1\n",
    "    return nb_blond_G / nb_G if nb_G > 0 else 0\n",
    "\n",
    "def ptg(data):\n",
    "    nb_T_G, nb_G = 0, 0\n",
    "    for ligne in data:\n",
    "        for indiv in ligne:\n",
    "            if indiv[2] == 'G':\n",
    "                nb_G += 1\n",
    "                if indiv[1] == 'T':\n",
    "                    nb_T_G += 1\n",
    "    return nb_T_G / nb_G if nb_G > 0 else 0\n",
    "\n",
    "def pbp(data):\n",
    "    nb_blond_P, nb_P = 0, 0\n",
    "    for ligne in data:\n",
    "        for indiv in ligne:\n",
    "            if indiv[2] == 'P':\n",
    "                nb_P += 1\n",
    "                if indiv[0] == 'B':  # cheveux blonds\n",
    "                    nb_blond_P += 1\n",
    "    return nb_blond_P / nb_P if nb_P > 0 else 0\n",
    "\n",
    "def ptp(data):\n",
    "    nb_T_P, nb_P = 0, 0\n",
    "    for ligne in data:\n",
    "        for indiv in ligne:\n",
    "            if indiv[2] == 'P':\n",
    "                nb_P += 1\n",
    "                if indiv[1] == 'T':\n",
    "                    nb_T_P += 1\n",
    "    return nb_T_P / nb_P if nb_P > 0 else 0\n",
    "\n",
    "def pbtg(data):\n",
    "    return pbg(data) * ptg(data)\n",
    "\n",
    "def pbtp(data):\n",
    "    return pbp(data) * ptp(data)\n",
    "\n",
    "def pbt(data):\n",
    "    # P(B,T) = somme des cas pour G et P\n",
    "    # Nous appliquons la loi des proba totales, vu qu'on veut les individus \n",
    "    # avec des cheveux B et une hauteur T quelque soit la nationalité\n",
    "    \n",
    "    return pbtg(data) * pg(data) + pbtp(data) * pp(data)\n",
    "\n",
    "\n",
    "# -------------------------Fonction générale------------------#\n",
    "\n",
    "\n",
    "def classer_individu(data):\n",
    "    # probas a posteriori\n",
    "    p_G = (pg(data) * pbtg(data)) / pbt(data)\n",
    "    p_P = (pp(data) * pbtp(data)) / pbt(data)\n",
    "\n",
    "    if p_G > p_P:\n",
    "        return f\"Nationalité G avec une proba Max de {p_G}\"\n",
    "    elif p_P > p_G:\n",
    "        return f\"Nationalité P avec une proba Max de {p_P}\"\n",
    "    else:\n",
    "        return \"Indécis (égalité)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbacbd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalité P avec une proba Max de 0.510296618174948'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classer_individu(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d9ee8",
   "metadata": {},
   "source": [
    "### Conclusion sur la nationalité avec la première approche: \n",
    "\n",
    "Nous voyons que la probabilité de la nationalité P est celle trouvé comme plus grande "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f8253",
   "metadata": {},
   "source": [
    "## Reprenons la fonction cette fois sans utiliser le théorème de naive bayes\n",
    "\n",
    "Il sera question maintenant de faire le calcul de proba conditionnelle\n",
    "\n",
    "P(G/B,T) = P(B,T,G)/P(B,T) un peu comme la proba de l'intersection de G avec (B,T) divisé par P(B,T)\n",
    "\n",
    "Ici il s'agit de compter le nombre de fois qu'on a un individu B, T, G et diviser par le nombre d'individu total ensuit diviser par le calul du nombre de personnes aux cheveux B et une hauteur T et diviser par le nombre total d'individus \n",
    "\n",
    "P(P/B,T): on fait pareil sur la nationalité P, on regarde le max et on conclu sur la nationalité "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a29102a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions utilitaires pour cette deuxième version qui n'utilise pas le théorème de Bayes \n",
    "\n",
    "\"\"\"\n",
    "Ici, on calcule directement les probabilités par comptage dans le jeu de données.\n",
    "\n",
    "Formules (probabilité conditionnelle par fréquence):\n",
    "\n",
    "P(G / B,T) = P(B,T,G) / P(B,T) \n",
    "P(B,T,G) = nombre d'individus (B,T,G) / nombre total d'individus\n",
    "P(B,T)   = nombre d'individus (B,T,*) / nombre total d'individus\n",
    "\n",
    "P(P / B,T) = P(B,T,P) / P(B,T) \n",
    "P(B,T,P) = nombre d'individus (B,T,P) / nombre total d'individus\n",
    "\"\"\"\n",
    "\n",
    "def pbtg_v2(data):\n",
    "    nb_BTG = 0\n",
    "    nb_Total = len(data) * len(data[0])\n",
    "    for ligne in data:\n",
    "        for indiv in ligne: \n",
    "            if indiv[0] == 'B' and indiv[1] == 'T' and indiv[2] == 'G':\n",
    "                nb_BTG += 1\n",
    "    return nb_BTG / nb_Total if nb_Total > 0 else 0\n",
    "\n",
    "def pbtp_v2(data):\n",
    "    nb_BTP = 0\n",
    "    nb_Total = len(data) * len(data[0])\n",
    "    for ligne in data:\n",
    "        for indiv in ligne: \n",
    "            if indiv[0] == 'B' and indiv[1] == 'T' and indiv[2] == 'P':\n",
    "                nb_BTP += 1\n",
    "    return nb_BTP / nb_Total if nb_Total > 0 else 0\n",
    "\n",
    "def pbt_v2(data):\n",
    "    nb_BT = 0\n",
    "    nb_Total = len(data) * len(data[0])\n",
    "    for ligne in data:\n",
    "        for indiv in ligne: \n",
    "            if indiv[0] == 'B' and indiv[1] == 'T':  # Nationalité indifférente\n",
    "                nb_BT += 1\n",
    "    return nb_BT / nb_Total if nb_Total > 0 else 0\n",
    "\n",
    "def classer_individu_v2(data):\n",
    "    p_G = pbtg_v2(data) / pbt_v2(data) if pbt_v2(data) > 0 else 0\n",
    "    p_P = pbtp_v2(data) / pbt_v2(data) if pbt_v2(data) > 0 else 0\n",
    "    \n",
    "    if p_G > p_P:\n",
    "        return f\"Nationalité G avec proba:  (p={p_G:.3f})\"\n",
    "    elif p_P > p_G:\n",
    "        return f\"Nationalité P avec proba: (p={p_P:.3f})\"\n",
    "    else:\n",
    "        return f\"Indécis (égalité, la proba est: p={p_G:.3f})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8ab6824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalité P avec proba: (p=0.560)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classer_individu_v2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f47da",
   "metadata": {},
   "source": [
    "### Commentaire:\n",
    "\n",
    "Avec notre jeu de données, on constate que les deux approches disent que l'individu est de nationalité P bien que nous remarquons que la probabilité avec la seconde approche semble être plus grande \n",
    "\n",
    "La différence entre les deux approches est que la première est plus stable, c'est moins probable d'avoir des 0 comme avec la deuxième approche. En effet, P(B,T/G) avec la deuxième approche vu qu'on calcul P(B,T,G), c'est parfois difficile d'avoir cette combinaison dans le jeu de donnée, ce qui n'est pas le cas lorsqu'on suppose l'indépendance entre les variables et qu'on applique la formule P(B/G)*P(T/G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ad9782",
   "metadata": {},
   "source": [
    "## D- Estimateur de Maximum de Vraisemblance : MLE\n",
    "\n",
    "Il est question dans cette partie de trouver la classe qui maximise plutôt cette probabilité : P((B,T)/nationalité)\n",
    "\n",
    "Donc *P(observation/classe)*:\n",
    "- P((B,T)/P) : la nationalité P\n",
    "- P((B,T)/G) : la nationalité G\n",
    "\n",
    "Nous devons faire ceci en utilisant deux approches:\n",
    "1. En tenant compte du cadre bayes naïf\n",
    "P(B,T/G) = P(B/G)*P(T/G) comme donné dans l'énnoncé du TP pareil pour P(B,T/P)\n",
    "2. Sans tenir compte du cadre bayes naïf\n",
    "\n",
    "    Ici on fonctionnera par comptage dans notre matrice de données, comme avec l'exemple donné dans l'énnoncé du TP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aeef542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24319759804841432\n"
     ]
    }
   ],
   "source": [
    "pbtg_sans_naif = pbg(data)*ptg(data)\n",
    "\n",
    "print(pbtg_sans_naif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "618c7f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24025974025974026\n"
     ]
    }
   ],
   "source": [
    "pbtp_sans_naif = pbp(data)*ptp(data)\n",
    "\n",
    "print(pbtp_sans_naif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5eeba",
   "metadata": {},
   "source": [
    "#### Fonction plus générale qui prend en entrée les données et les deux paramètres (couleur_cheveux, hauteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "baa08d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le code pour répondre à la question avec la première approche est le suivant \n",
    "\n",
    "\n",
    "# Notre fonction est un peu plus générale, nous allons lui passer les données, la couleur des cheveux B et la hauteur T pour voir \n",
    "# la classe qui maximise la vraisemblance \n",
    "def mle_naif(data, cheveux, hauteur):\n",
    "    # Comptage des individus par classe\n",
    "    # On récupère de manière individuelle les classes présentes dans les données\n",
    "    classes = set(indiv[2] for ligne in data for indiv in ligne)\n",
    "\n",
    "    # où on pourra stocker les vraissemblances calculées et retenir la valeur maximale \n",
    "    vraisemblances = {}\n",
    "\n",
    "    # rappel: le triplet (B,T,G) est dans l'ordre des caractéristiques (cheveux, hauteur et nationalité)\n",
    "    \n",
    "    for c in classes:\n",
    "        nb_c = sum(indiv[2] == c for ligne in data for indiv in ligne)\n",
    "        nb_cheveux_c = sum(indiv[2] == c and indiv[0] == cheveux for ligne in data for indiv in ligne)\n",
    "        nb_hauteur_c = sum(indiv[2] == c and indiv[1] == hauteur for ligne in data for indiv in ligne)\n",
    "        \n",
    "        p_cheveux = nb_cheveux_c / nb_c if nb_c > 0 else 0\n",
    "        p_hauteur  = nb_hauteur_c / nb_c if nb_c > 0 else 0\n",
    "        \n",
    "        vraisemblances[c] = p_cheveux * p_hauteur\n",
    "    \n",
    "    # Choisir la classe qui maximise P(x|c)\n",
    "    best_class = max(vraisemblances, key=vraisemblances.get)\n",
    "    return best_class, vraisemblances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2ee8c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distribution de vraisemblance entre les classes est: {'G': 0.24319759804841432, 'P': 0.24025974025974026} \n",
      "La nationalité finale est: G\n"
     ]
    }
   ],
   "source": [
    "## Test de notre fonction pour répondre à la question\n",
    "\n",
    "print(f\"La distribution de vraisemblance entre les classes est: {mle_naif(data=data, cheveux='B', hauteur='T')[1]} \\nLa nationalité finale est: {mle_naif(data=data, cheveux='B', hauteur='T')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd841ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Si on utilisait nos fonctions définies plus haut, voici comment serait simplement le code \n",
    "\n",
    "def mle_naif_v2(data):\n",
    "\n",
    "    # on calcul P(B,T/G) = P(B/G)*P(T/G) on l'appellera p1\n",
    "    p1 = pbg(data)*ptg(data)\n",
    "\n",
    "    # On calcul ensuite P(B,T/P) = P(B/P) * P(T/P) on l'appellera p2\n",
    "    p2 = pbp(data)*ptp(data)\n",
    "    \n",
    "    # comparaison et choix de la nationalité \n",
    "    if p1 > p2:\n",
    "        print(f\"L'individu (B,T) est de nationalité G avec une vraisemblance de {p1}\")\n",
    "    else:\n",
    "        print(f\"L'individu (B,T) est de nationalité P avec une vraisemblance de {p2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "955bdf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'individu (B,T) est de nationalité G avec une vraisemblance de 0.24319759804841432\n"
     ]
    }
   ],
   "source": [
    "## Application \n",
    "mle_naif_v2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ff8e3",
   "metadata": {},
   "source": [
    "### MLE : approche sans l'utilisation de bayes naïf \n",
    "\n",
    "Comme nous allons estimer directement dans les données (par comptage, pas par produit), nous n'aurons pas besoin des fonctions de MAP que nous avons fait plus haut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0a9aa278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le code pour répondre à la question avec la deuxième approche est le suivant\n",
    "\n",
    "def mle_sans_naif(data, cheveux, hauteur):\n",
    "    classes = set(indiv[2] for ligne in data for indiv in ligne)\n",
    "    vraisemblances = {}\n",
    "    \n",
    "    for c in classes:\n",
    "        nb_c = sum(indiv[2] == c for ligne in data for indiv in ligne)\n",
    "        nb_obs_c = sum(indiv[2] == c and indiv[0] == cheveux and indiv[1] == hauteur \n",
    "                       for ligne in data for indiv in ligne)\n",
    "        \n",
    "        vraisemblances[c] = nb_obs_c / nb_c if nb_c > 0 else 0\n",
    "    \n",
    "    best_class = max(vraisemblances, key=vraisemblances.get)\n",
    "    return best_class, vraisemblances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01851056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distribution des proba entre les classes est: {'G': 0.22602739726027396, 'P': 0.2727272727272727} \n",
      "La nationalité finale est: P\n"
     ]
    }
   ],
   "source": [
    "# Application de la fonction avec le cas (B,T,G)\n",
    "\n",
    "print(f\"La distribution des proba entre les classes est: {mle_sans_naif(data=data, cheveux='B', hauteur='T')[1]} \\nLa nationalité finale est: {mle_sans_naif(data=data, cheveux='B', hauteur='T')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff9d13",
   "metadata": {},
   "source": [
    "## E- Point de vue continu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036e919",
   "metadata": {},
   "source": [
    "Dans ce cadre, on suppose que la mesure de la couleur des cheveux n’est plus binaire (B ou D) mais une variable continue notée intensité appartenant à [0,1] :\n",
    "\n",
    "- 0 = blond pur\n",
    "- 1 = dark pur\n",
    "- Entre les deux, ce sont des valeurs intermédiaires.\n",
    "\n",
    "1. Génération du jeu de données\n",
    "\n",
    "Nous avons engender ce nouveau jeu de données avec la fonction qui génère aléatoirement des triplets (intensité, hauteur, pays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "617857d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.63943, 'T', 'P'), (0.24489, 'T', 'G'), (0.6767, 'T', 'P'), (0.03178, 'T', 'G'), (0.23266, 'T', 'G'), (0.71602, 'S', 'G'), (0.44921, 'S', 'G'), (0.75881, 'T', 'P'), (0.34025, 'T', 'G'), (0.95721, 'S', 'G')]\n",
      "[(0.09275, 'T', 'P'), (0.84749, 'S', 'G'), (0.72973, 'T', 'P'), (0.0788, 'S', 'P'), (0.57735, 'T', 'G'), (0.66126, 'S', 'G'), (0.85532, 'T', 'P'), (0.27797, 'S', 'G'), (0.37018, 'T', 'P'), (0.70182, 'T', 'G')]\n",
      "[(0.53414, 'T', 'G'), (0.46226, 'S', 'G'), (0.68461, 'T', 'G'), (0.8218, 'S', 'P'), (0.26774, 'T', 'P'), (0.21263, 'S', 'P'), (0.88468, 'S', 'G'), (0.26488, 'T', 'P'), (0.74701, 'S', 'P'), (0.362, 'T', 'P')]\n",
      "[(0.09091, 'T', 'G'), (0.15284, 'T', 'P'), (0.59641, 'S', 'P'), (0.59589, 'S', 'P'), (0.97108, 'T', 'G'), (0.68171, 'S', 'P'), (0.11155, 'S', 'G'), (0.45372, 'S', 'G'), (0.50768, 'T', 'P'), (0.84167, 'T', 'G')]\n",
      "[(0.37391, 'T', 'G'), (0.59894, 'S', 'G'), (0.11187, 'S', 'P'), (0.23945, 'T', 'G'), (0.08565, 'S', 'G'), (0.97798, 'T', 'G'), (0.65975, 'T', 'P'), (0.52767, 'S', 'G'), (0.92891, 'T', 'P'), (0.39899, 'S', 'P')]\n",
      "[(0.89961, 'S', 'G'), (0.24791, 'T', 'P'), (0.02103, 'T', 'G'), (0.00719, 'T', 'G'), (0.0674, 'T', 'P'), (0.07086, 'T', 'P'), (0.66898, 'T', 'G'), (0.72335, 'S', 'G'), (0.78462, 'S', 'G'), (0.09433, 'S', 'P')]\n",
      "[(0.42358, 'S', 'G'), (0.67336, 'T', 'G'), (0.40262, 'S', 'G'), (0.24866, 'T', 'P'), (0.14018, 'T', 'P'), (0.46263, 'T', 'P'), (0.80802, 'T', 'G'), (0.65214, 'T', 'G'), (0.92637, 'T', 'G'), (0.40641, 'S', 'G')]\n",
      "[(0.86465, 'T', 'G'), (0.37897, 'S', 'P'), (0.92652, 'S', 'P'), (0.42301, 'S', 'G'), (0.1899, 'T', 'G'), (0.57918, 'T', 'P'), (0.05717, 'S', 'G'), (0.05688, 'T', 'G'), (0.06852, 'T', 'G'), (0.40378, 'T', 'G')]\n",
      "[(0.61938, 'S', 'P'), (0.93471, 'T', 'P'), (0.23869, 'S', 'G'), (0.67169, 'S', 'P'), (0.31618, 'T', 'G'), (0.45829, 'T', 'G'), (0.53763, 'S', 'G'), (0.93326, 'T', 'G'), (0.36953, 'T', 'P'), (0.83374, 'S', 'G')]\n",
      "[(0.66786, 'S', 'G'), (0.93893, 'T', 'P'), (0.11543, 'T', 'G'), (0.27235, 'T', 'P'), (0.2036, 'S', 'P'), (0.25112, 'T', 'G'), (0.63428, 'S', 'G'), (0.00355, 'T', 'P'), (0.16158, 'S', 'P'), (0.56091, 'T', 'G')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generer_matrice_continu(n_lignes, n_colonnes):\n",
    "    matrice = []\n",
    "    for _ in range(n_lignes):\n",
    "        ligne = []\n",
    "        for _ in range(n_colonnes):\n",
    "            intensite = round(random.uniform(0, 1), 5)  # valeur continue arrondie\n",
    "            hauteur = random.choice(['T', 'S'])\n",
    "            pays = random.choice(['G', 'P'])\n",
    "            ligne.append((intensite, hauteur, pays))\n",
    "        matrice.append(ligne)\n",
    "    return matrice\n",
    "\n",
    "# créons la matrice 10x10 qui contiendra 100 données \n",
    "random.seed(42)\n",
    "data_continu = generer_matrice_continu(10, 10)\n",
    "\n",
    "# Affichage\n",
    "for ligne in data_continu:\n",
    "    print(ligne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7ed80",
   "metadata": {},
   "source": [
    "2. Explication \n",
    "\n",
    "Dans ce contexte, la couleur des cheveux devient une variable continue, notée x, représentant une intensité comprise entre 0 et 1.\n",
    "La formule de la vraisemblance s’écrit alors :\n",
    "\n",
    "P(x,hauteur∣pays)=f(x∣pays)×P(hauteur∣pays)\n",
    "\n",
    "où :\n",
    "f(x∣pays) est la densité de probabilité de la variable continue x, que nous allons modéliser par une loi normale (gaussienne),\n",
    "\n",
    "P(hauteur∣pays) reste une probabilité discrète estimée comme une fréquence, comme dans les questions précédentes.\n",
    "\n",
    "Le principe du Maximum de Vraisemblance (MLE) consistera toujours à choisir le pays qui maximise cette vraisemblance P(x,hauteur∣pays).\n",
    "\n",
    "Pour le cas du Maximum a posteriori (MAP), on multipliera en plus par la probabilité a priori du pays P(pays), comme dans la première partie.\n",
    "\n",
    "Donc voici en gros comment nous allons fonctionner \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b84184",
   "metadata": {},
   "source": [
    "3. Modifications dans les fonctions Python\n",
    "\n",
    "Dans les fonctions précédentes, on calculait P(B/G) avec la fonction pbg en comptant le nombre de personnes de hauteur G avec la couleur des cheveux Blond divisé par le nombre personne de hauteur G. Mais ici on va devoir remplacer cela par la fonction de densité gausienne f(x/G).\n",
    "\n",
    "On pourra estimer les moyennes et l'écart-type des intensités de cheveux des individus de nationalité G par le MLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ecfc36b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'individu est de la nationalité P avec une vraisemblance de 0.6950617016358651\n"
     ]
    }
   ],
   "source": [
    "## On remplace pbg par cette version dans le cas continu\n",
    "import math\n",
    "\n",
    "def pbg_continu(data, x):\n",
    "    # On extrait les intensités de cheveux pour la nationalité G\n",
    "    cheveux_G = [indiv[0] for ligne in data for indiv in ligne if indiv[2] == 'G']\n",
    "    if not cheveux_G:\n",
    "        return 0\n",
    "    \n",
    "    mu_G = sum(cheveux_G) / len(cheveux_G)\n",
    "    sigma_G = math.sqrt(sum((c - mu_G)**2 for c in cheveux_G) / len(cheveux_G))\n",
    "    \n",
    "    # Densité gaussienne évaluée en x\n",
    "    return (1 / (math.sqrt(2 * math.pi) * sigma_G)) * math.exp(-((x - mu_G)**2) / (2 * sigma_G**2))\n",
    "\n",
    "# On fait pareil pour pbp \n",
    "\n",
    "\n",
    "\n",
    "def pbp_continu(data, x):\n",
    "    # On extrait les intensités de cheveux pour la nationalité P\n",
    "    cheveux_P = [indiv[0] for ligne in data for indiv in ligne if indiv[2] == 'P']\n",
    "    if not cheveux_P:\n",
    "        return 0\n",
    "    \n",
    "    mu_P = sum(cheveux_P) / len(cheveux_P)\n",
    "    sigma_P = math.sqrt(sum((c - mu_P)**2 for c in cheveux_P) / len(cheveux_P))\n",
    "    \n",
    "    # Densité gaussienne évaluée en x\n",
    "    return (1 / (math.sqrt(2 * math.pi) * sigma_P)) * math.exp(-((x - mu_P)**2) / (2 * sigma_P**2))\n",
    "\n",
    "# Nous allons utiliser ptg() et ptp() que nous avons définie dans la première partie \n",
    "\n",
    "# Maintenant avec ces fonctions, on va simplement remplacer le calcul de p1 et p2 qu'on faisait comme ceci:\n",
    "#p1 = pbg(data) * ptg(data)\n",
    "#p2 = pbp(data) * ptp(data)\n",
    "\n",
    "# Par ceci: \n",
    "#p1 = pbg_continu(data, x) * ptg(data)\n",
    "#p2 = pbp_continu(data, x) * ptp(data)\n",
    "\n",
    "# Il faut remplacer x par une valeur continue quelconque qu'on aimerait prendre pour prédire la nationalité \n",
    "\n",
    "# Application des fonctions et prédiction de la nationalité \n",
    "\n",
    "# Nous allons prendre la première valeur de data_continu\n",
    "x = data_continu[0][0][0]\n",
    "\n",
    "# Calcul des proba \n",
    "p1 = pbg_continu(data_continu, x) * ptg(data_continu)\n",
    "p2 = pbp_continu(data_continu, x) * ptp(data_continu)\n",
    "\n",
    "# Affichage de la nationalité \n",
    "if p1 > p2:\n",
    "    print(f\"L'individu est de la nationalité G avec une vraisemblance de {p1}\")\n",
    "else:\n",
    "    print(f\"L'individu est de la nationalité P avec une vraisemblance de {p2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a673f035",
   "metadata": {},
   "source": [
    "### Le calcul du MLE que nous avons fait prenait en compte l'utilisation de bayes naif\n",
    "\n",
    "Maintenant nous aimerons bien calculer P(x,T/G) ou P(x,T/P) sans dissocier comme nous permet bayes naif à l'aide de l'hypothèse d'indépendance entre les données\n",
    "\n",
    "Nous allons faire une fonction qui prend en paramètre le pays aussi afin de calculer les deux proba et comparer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530d0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'individu est de la nationalité P avec une vraisemblance de 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "# Il s'agit donc de calculer ici les occurences d'individus qui ont ces caractéristiques (x,T) simulatanément \n",
    "\n",
    "def p_joint_continu(data, x, taille, pays, tol=0.05):\n",
    "    # tol : tolérance autour de x pour \"approximer\" un intervalle continu\n",
    "\n",
    "    individus_classe = []\n",
    "    for ligne in data:\n",
    "        for indiv in ligne:\n",
    "            if indiv[2] == pays:\n",
    "                individus_classe.append(indiv)\n",
    "\n",
    "    if not individus_classe:\n",
    "        return 0\n",
    "\n",
    "    # Comptage des individus proches de x et de taille donnée\n",
    "    nb_total = len(individus_classe)\n",
    "    nb_voisins = sum(\n",
    "        1 for indiv in individus_classe\n",
    "        if abs(indiv[0] - x) < tol and indiv[1] == taille\n",
    "    )\n",
    "\n",
    "    return nb_voisins / nb_total\n",
    "\n",
    "# Application du calcul \n",
    "p1 = p_joint_continu(data_continu, x, 'T', 'G')\n",
    "p2 = p_joint_continu(data_continu, x, 'T', 'P')\n",
    "\n",
    "if p1 > p2:\n",
    "    print(f\"L'individu est de la nationalité G avec une vraisemblance de {p1}\")\n",
    "else:\n",
    "    print(f\"L'individu est de la nationalité P avec une vraisemblance de {p2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70fc5b",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "On constate bien que la proba ici est plus petite que la proba en utilisant bayes naif, ceci s'explique toujours par la rareté des évènements qui sont à la fois (x,T) dans ce jeu de données, supposer l'indépendance entre les données rend la solution plus stable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73ae65",
   "metadata": {},
   "source": [
    "### Application de ceci au calcul du MAP à présent \n",
    "\n",
    "Pour le MAP, il suffira d'ajouter la multiplication de P(pays) dans la formule P(x,T/pays) = f(x/pays).P(T/pays).P(pays)\n",
    "\n",
    "Ainsi la proba pourra utiliser ce qu'on a calculé précédemment et ajouter juste P(pays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1c76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'individu est probablement de nationalité G avec une probabilité proportionnelle à 0.39163171191109775\n"
     ]
    }
   ],
   "source": [
    "# Calcul des probabilités a priori\n",
    "# Nous avions déjà calculé cela dans les parties précédentes P(pays) avec pays = 'G' / 'P' \n",
    "# pour rappel pg = p(pays=G) et pp = p(pays=P)\n",
    "\n",
    "# Calcul MAP\n",
    "p1_map = pbg_continu(data_continu, x) * ptg(data_continu) * pg(data_continu)\n",
    "p2_map = pbp_continu(data_continu, x) * ptp(data_continu) * pp(data_continu)\n",
    "\n",
    "if p1_map > p2_map:\n",
    "    print(f\"L'individu est probablement de nationalité G avec une probabilité proportionnelle à {p1_map}\")\n",
    "else:\n",
    "    print(f\"L'individu est probablement de nationalité P avec une probabilité proportionnelle à {p2_map}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
